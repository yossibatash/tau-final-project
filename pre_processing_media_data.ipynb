{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a3e3d88",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# !pip install findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "18ea4a5a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3d96d20f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import from_json\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "          .appName('pre_process_media_data') \\\n",
    "          .getOrCreate()\n",
    "\n",
    "spark.conf.set(\"spark.sql.session.timeZone\", \"UTC\")\n",
    "\n",
    "create_dim_time_csv = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a6fcae",
   "metadata": {},
   "source": [
    "## Create Dim Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bb40265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already created dim time CSV file\n"
     ]
    }
   ],
   "source": [
    "# One time create a dim time csv file\n",
    "# ------------------------------------------------\n",
    "import pandas as pd  \n",
    "\n",
    "# from pyspark.sql.functions import from_unixtime, col\n",
    "from datetime import datetime\n",
    "\n",
    "if create_dim_time_csv:\n",
    "    # Define start and end timestamps\n",
    "    start_timestamp = 1640995200 # 2022-01-01 00:00:00\n",
    "    end_timestamp = 1683014400   # 2023-06-30 23:59:59\n",
    "\n",
    "    # list of name, degree, score \n",
    "    rows = list(range(start_timestamp, end_timestamp + 60, 60))\n",
    "\n",
    "    # dictionary of lists  \n",
    "    dict = {'epoch': rows}  \n",
    "\n",
    "    df = pd.DataFrame(dict) \n",
    "\n",
    "    # saving the dataframe \n",
    "    df.to_csv('./data/STG/datetime_data/dim_time.csv') \n",
    "else:\n",
    "    print(\"Already created dim time CSV file\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "665b3661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- epoch: integer (nullable = true)\n",
      " |-- ts_: string (nullable = true)\n",
      " |-- date_: date (nullable = true)\n",
      " |-- year_: integer (nullable = true)\n",
      " |-- month_: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- day_of_month: integer (nullable = true)\n",
      " |-- time_: string (nullable = true)\n",
      " |-- hour_: integer (nullable = true)\n",
      " |-- minute_: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Read dim time csv file\n",
    "# ------------------------------------------------\n",
    "schema = StructType([\n",
    "StructField(\"index\", IntegerType()),\n",
    "    StructField(\"epoch\", IntegerType())                   \n",
    "])\n",
    "\n",
    "# Read csv files\n",
    "time_df = spark.read \\\n",
    "        .option(\"header\",True) \\\n",
    "        .csv(\"./data/STG/datetime_data/dim_time.csv\", schema=schema)\n",
    "\n",
    "# Adding timestamp column\n",
    "time_df = time_df.withColumn(\"ts_\",F.from_unixtime(\"epoch\"))\n",
    "\n",
    "# This column capture the date.\n",
    "time_df = time_df.withColumn(\"date_\",F.to_date(\"ts_\"))\n",
    "\n",
    "# This column capture the year.\n",
    "time_df = time_df.withColumn(\"year_\", F.year(\"ts_\"))\n",
    "\n",
    "# This column capture the month.\n",
    "time_df = time_df.withColumn(\"month_\", F.month(\"ts_\"))\n",
    "\n",
    "# # This column capture the day in the week.\n",
    "time_df = time_df.withColumn(\"day_of_week\", F.date_format(\"ts_\", 'E'))\n",
    "\n",
    "# # This column capture the day in the month.\n",
    "time_df = time_df.withColumn(\"day_of_month\", F.dayofmonth(\"ts_\"))\n",
    "\n",
    "# This column capture the time.\n",
    "time_df = time_df.withColumn(\"time_\", F.date_format('ts_', 'HH:mm:ss'))\n",
    "\n",
    "# This column capture the hour.\n",
    "time_df = time_df.withColumn(\"hour_\",F.hour(\"ts_\"))\n",
    "\n",
    "# This column capture the minute.\n",
    "time_df = time_df.withColumn(\"minute_\", F.minute(\"ts_\"))\n",
    "\n",
    "time_df.createOrReplaceTempView(\"time_df\")\n",
    "\n",
    "time_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "271f14af",
   "metadata": {},
   "source": [
    "## Load Media Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8782eb3b",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 53:===========================================>       (1802 + 10) / 2102]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- url: string (nullable = true)\n",
      " |-- time_published: string (nullable = true)\n",
      " |-- ticker_sentiment: string (nullable = true)\n",
      " |-- filename: string (nullable = false)\n",
      " |-- file_ticker: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 53:================================================>  (2004 + 10) / 2102]\r",
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# CSV File Schema\n",
    "schema = StructType([\n",
    "StructField(\"title\"                  , StringType()),   \n",
    "StructField(\"url\"                    , StringType()), \n",
    "StructField(\"time_published\"         , StringType()),             \n",
    "StructField(\"authors\"                , StringType()),     \n",
    "StructField(\"summary\"                , StringType()),     \n",
    "StructField(\"banner_image\"           , StringType()),           \n",
    "StructField(\"source\"                 , StringType()),     \n",
    "StructField(\"category_within_source\" , StringType()),                     \n",
    "StructField(\"source_domain\"          , StringType()),           \n",
    "StructField(\"topics\"                 , StringType()),     \n",
    "StructField(\"overall_sentiment_score\", StringType()),                     \n",
    "StructField(\"overall_sentiment_label\", StringType()),                     \n",
    "StructField(\"ticker_sentiment\"       , StringType())                   \n",
    "])\n",
    "\n",
    "# Read csv files\n",
    "df = spark.read \\\n",
    "        .option(\"header\",True) \\\n",
    "        .option(\"multiline\",True) \\\n",
    "        .option(\"quote\", \"\\\"\") \\\n",
    "        .option(\"escape\", \"\\\"\") \\\n",
    "        .csv(\"./data/alpha_vantage/news_data/*/*\", schema=schema)\n",
    "\n",
    "df = df.select(F.col(\"url\"),\n",
    "       F.col(\"time_published\"),\n",
    "       F.col(\"ticker_sentiment\"))\n",
    "\n",
    "df = df.withColumn(\"filename\", F.input_file_name())\n",
    "\n",
    "df = df.withColumn('file_ticker', F.split(df['filename'], '/').getItem(9))\n",
    "\n",
    "df.printSchema()\n",
    "\n",
    "df.createOrReplaceTempView(\"df\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f98b193",
   "metadata": {},
   "source": [
    "# Check how many files we have per ticker\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "357672eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check how many files we have per ticker\n",
    "files_per_ticker_df = spark.sql(\"\"\"\n",
    "select  ROW_NUMBER() OVER (ORDER BY count(*) desc) AS ROWNUM,\n",
    "        file_ticker, count(*)\n",
    "from df\n",
    "group by 2\n",
    "order by 3 desc\n",
    "\"\"\")\n",
    "\n",
    "# +------+-----------+--------+\n",
    "# |ROWNUM|file_ticker|count(1)|\n",
    "# +------+-----------+--------+\n",
    "# |1     |TSLA       |10227   |\n",
    "# |2     |JPM        |9954    |\n",
    "# |3     |AAPL       |9491    |\n",
    "# |4     |NFLX       |8994    |\n",
    "# |5     |BAC        |8634    |\n",
    "# |6     |MSFT       |8617    |\n",
    "# |7     |WFC        |7666    |\n",
    "# |8     |META       |7402    |\n",
    "# |9     |WMT        |7018    |\n",
    "# |10    |AMZN       |6792    |\n",
    "# |11    |PFE        |5708    |\n",
    "# |12    |NVDA       |5684    |\n",
    "# |13    |XOM        |3814    |\n",
    "# |14    |NKE        |3670    |\n",
    "# |15    |KO         |3376    |\n",
    "# |16    |JNJ        |3171    |\n",
    "# |17    |VZ         |2875    |\n",
    "# |18    |MA         |2611    |\n",
    "# |19    |COST       |2560    |\n",
    "# |20    |DIS        |2472    |\n",
    "# |21    |ABBV       |2430    |\n",
    "# |22    |CVX        |2378    |\n",
    "# |23    |HD         |2216    |\n",
    "# |24    |PEP        |2180    |\n",
    "# |25    |PG         |1812    |\n",
    "# |26    |MCD        |1757    |\n",
    "# |27    |CSCO       |1724    |\n",
    "# |28    |UNH        |1681    |\n",
    "# |29    |AVGO       |1649    |\n",
    "# |30    |ACN        |1557    |\n",
    "# |31    |V          |1375    |\n",
    "# |32    |ADBE       |963     |\n",
    "# |33    |ABT        |932     |\n",
    "# |34    |TMO        |760     |\n",
    "# |35    |PM         |722     |\n",
    "# |36    |LLY        |703     |\n",
    "# |37    |DHR        |443     |\n",
    "# |38    |TXN        |434     |\n",
    "# |39    |LIN        |213     |\n",
    "# +------+-----------+--------+\n",
    "\n",
    "files_per_ticker_df.createOrReplaceTempView('files_per_ticker_df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "654cfe1e",
   "metadata": {},
   "source": [
    "# Parse ticker_sentiment JSON data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "55425808",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- url: string (nullable = true)\n",
      " |-- time_published: string (nullable = true)\n",
      " |-- ticker: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = ArrayType(\n",
    "    StructType([StructField(\"ticker\", StringType()), \n",
    "                StructField(\"relevance_score\", StringType()), \n",
    "                StructField(\"ticker_sentiment_score\", StringType()), \n",
    "                StructField(\"ticker_sentiment_label\", StringType())]))\n",
    "\n",
    "\n",
    "df = df.withColumn(\"ticker_sentiment_new\", from_json(F.col(\"ticker_sentiment\"), schema))\n",
    "\n",
    "df = df.withColumn(\"ticker_sentiment_item\",F.explode(F.col(\"ticker_sentiment_new\")))\n",
    "\n",
    "df = df.withColumn(\"ticker\", F.col(\"ticker_sentiment_item\").getItem(\"ticker\"))\n",
    "\n",
    "df = df.withColumn(\"relevance_score\", F.col(\"ticker_sentiment_item\").getItem(\"relevance_score\"))\n",
    "\n",
    "df = df.withColumn(\"ticker_sentiment_score\", F.col(\"ticker_sentiment_item\").getItem(\"ticker_sentiment_score\"))\n",
    "\n",
    "df = df.withColumn(\"ticker_sentiment_label\", F.col(\"ticker_sentiment_item\").getItem(\"ticker_sentiment_label\"))\n",
    "\n",
    "df = df.select(F.col(\"url\"),\n",
    "               F.col(\"time_published\"),\n",
    "               F.col(\"ticker\"))\n",
    "\n",
    "df.printSchema()\n",
    "df.createOrReplaceTempView('df')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8119114",
   "metadata": {},
   "source": [
    "# Aggregate Ticker Media Events Count "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "98d076d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- url: string (nullable = true)\n",
      " |-- time_published: string (nullable = true)\n",
      " |-- ticker_count_per_article: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ticker_count_per_article_df = spark.sql(\"\"\"\n",
    "with top_tickers\n",
    "as \n",
    "(\n",
    "    select * \n",
    "    from files_per_ticker_df\n",
    "    where ROWNUM<36\n",
    "),\n",
    "s1\n",
    "as\n",
    "(\n",
    "    select url,\n",
    "           ticker,\n",
    "           min(time_published) as time_published     \n",
    "    from   df\n",
    "    group by 1,2\n",
    ")\n",
    "\n",
    "select s1.url,\n",
    "       s1.time_published,\n",
    "       count(s1.ticker) as ticker_count_per_article\n",
    "from   s1 join top_tickers\n",
    "       on s1.ticker = top_tickers.file_ticker \n",
    "group by 1,2\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "ticker_count_per_article_df.createOrReplaceTempView(\"ticker_count_per_article_df\")\n",
    "\n",
    "ticker_count_per_article_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b39d358a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- url: string (nullable = true)\n",
      " |-- t_article_published_date: string (nullable = false)\n",
      " |-- t_article_published_time: string (nullable = false)\n",
      " |-- t_article_published_ts: timestamp (nullable = true)\n",
      " |-- t_article_published_epoch: long (nullable = true)\n",
      " |-- ticker_count_per_article: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This column capture the year of the media article been published.\n",
    "ticker_count_per_article_df = ticker_count_per_article_df.withColumn(\"t_article_published_year\", \n",
    "                                                                     F.col(\"time_published\")[0:4])\n",
    "\n",
    "# This column capture the month of the media article been published.\n",
    "ticker_count_per_article_df = ticker_count_per_article_df.withColumn(\"t_article_published_month\", \n",
    "                                                                     F.col(\"time_published\")[5:2])\n",
    "\n",
    "# This column capture the day (in the month) of the media article been published.\n",
    "ticker_count_per_article_df = ticker_count_per_article_df.withColumn(\"t_article_published_day\", \n",
    "                                                                     F.col(\"time_published\")[7:2])\n",
    "\n",
    "# This column capture the hour of the media article been published.\n",
    "ticker_count_per_article_df = ticker_count_per_article_df.withColumn(\"t_article_published_hour\", \n",
    "                                                                     F.col(\"time_published\")[10:2])\n",
    "\n",
    "# This column capture the minute of the media article been published.\n",
    "ticker_count_per_article_df = ticker_count_per_article_df.withColumn(\"t_article_published_min\", \n",
    "                                                                     F.col(\"time_published\")[12:2])\n",
    "\n",
    "# This column capture the second of the media article been published.\n",
    "ticker_count_per_article_df = ticker_count_per_article_df.withColumn(\"t_article_published_sec\",\n",
    "                                                                     F.col(\"time_published\")[14:2])\n",
    "\n",
    "# This column capture the date of the media article.\n",
    "ticker_count_per_article_df = ticker_count_per_article_df.withColumn(\"t_article_published_date\", \n",
    "                                                                     F.concat_ws('-',\n",
    "                                                                                  F.col(\"t_article_published_year\"),\n",
    "                                                                                  F.col(\"t_article_published_month\"),\n",
    "                                                                                  F.col(\"t_article_published_day\")\n",
    "                                                                                )\n",
    "                                                                    )\n",
    "\n",
    "# This column capture the time of the media article.\n",
    "ticker_count_per_article_df = ticker_count_per_article_df.withColumn(\"t_article_published_time\", \n",
    "                                                                     F.concat_ws(':',\n",
    "                                                                                  F.col(\"t_article_published_hour\"),\n",
    "                                                                                  F.col(\"t_article_published_min\"),\n",
    "                                                                                  F.col(\"t_article_published_sec\")\n",
    "                                                                                )\n",
    "                                                                    )\n",
    "\n",
    "# This column capture the timestamp of the media article.\n",
    "ticker_count_per_article_df = ticker_count_per_article_df.withColumn(\"t_article_published_ts\", \n",
    "                                                                     F.to_timestamp(\n",
    "                                                                         F.concat_ws(' ',\n",
    "                                                                                     F.col(\"t_article_published_date\"),\n",
    "                                                                                     F.col(\"t_article_published_time\")\n",
    "                                                                                    )\n",
    "                                                                                   )\n",
    "                                                                    )\n",
    "\n",
    "# This column capture the time and date of the media article in epoch time.\n",
    "ticker_count_per_article_df = ticker_count_per_article_df.withColumn(\"t_article_published_epoch\", \n",
    "                                                                     F.unix_timestamp(\"t_article_published_ts\"))\n",
    "\n",
    "\n",
    "ticker_count_per_article_df = ticker_count_per_article_df.select(F.col(\"url\"),\n",
    "                                                                 F.col(\"t_article_published_date\"),    \n",
    "                                                                 F.col(\"t_article_published_time\"),\n",
    "                                                                 F.col(\"t_article_published_ts\"),\n",
    "                                                                 F.col(\"t_article_published_epoch\"),                                                                 \n",
    "                                                                 F.col(\"ticker_count_per_article\")\n",
    "                                                                )\n",
    "\n",
    "ticker_count_per_article_df.createOrReplaceTempView(\"ticker_count_per_article_df\")\n",
    "\n",
    "ticker_count_per_article_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0525c403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding for each time resolution (1,5,10,15,30 minute) the proper key (round up epoch key)\n",
    "\n",
    "before_agg_df = spark.sql(\"\"\"\n",
    "\n",
    "select url,\n",
    "       cast((t_article_published_epoch/60) as int)*60                 as  t_round_up_min_epoch,\n",
    "       ticker_count_per_article          \n",
    "from ticker_count_per_article_df\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "before_agg_df.createOrReplaceTempView(\"before_agg_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b4b4a627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- url: string (nullable = true)\n",
      " |-- t_round_up_min_epoch: integer (nullable = true)\n",
      " |-- ticker_count_per_article: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "before_agg_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c4e44575",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- epoch_key: integer (nullable = true)\n",
      " |-- snp_ticker_count_epoch: long (nullable = true)\n",
      "\n",
      "23/08/19 17:17:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:17:56 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 55:==========>                                            (13 + 11) / 67]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/19 17:18:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 55:===================================>                   (43 + 10) / 67]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/19 17:18:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:04 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 57:>                                                       (0 + 10) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/19 17:18:05 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:05 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+----------------------+\n",
      "|summary|           epoch_key|snp_ticker_count_epoch|\n",
      "+-------+--------------------+----------------------+\n",
      "|  count|               75246|                 75246|\n",
      "|   mean|1.6615252373271668E9|    2.0736916248039763|\n",
      "| stddev|   8741929.383566512|      2.16896227901843|\n",
      "|    min|          1646121600|                     1|\n",
      "|    25%|          1653915600|                     1|\n",
      "|    50%|          1661408760|                     1|\n",
      "|    75%|          1668697980|                     2|\n",
      "|    max|          1677444660|                    86|\n",
      "+-------+--------------------+----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Agregate data for 1 min resolution data sets.\n",
    "\n",
    "agg_1min_data = spark.sql(\"\"\"\n",
    "\n",
    "select t_round_up_min_epoch          as epoch_key, \n",
    "       sum(ticker_count_per_article) as snp_ticker_count_epoch\n",
    "from before_agg_df\n",
    "group by 1\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "agg_1min_data.printSchema()\n",
    "\n",
    "agg_1min_data.summary().show()\n",
    "\n",
    "agg_1min_data.createOrReplaceTempView(\"agg_1min_data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda843ff",
   "metadata": {},
   "source": [
    "# Union 1 min Agg With Media Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7d2b376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# agg_1min_data.count()\n",
    "# 75,246"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "10e80c9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- epoch: integer (nullable = true)\n",
      " |-- ts_: string (nullable = true)\n",
      " |-- date_: date (nullable = true)\n",
      " |-- year_: integer (nullable = true)\n",
      " |-- month_: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- day_of_month: integer (nullable = true)\n",
      " |-- time_: string (nullable = true)\n",
      " |-- hour_: integer (nullable = true)\n",
      " |-- minute_: integer (nullable = true)\n",
      " |-- snp_media_events_count: long (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "before_win_df = spark.sql(\"\"\"\n",
    "select t.*,\n",
    "       coalesce(a.snp_ticker_count_epoch,0) as snp_media_events_count\n",
    "from   time_df as t\n",
    "       left join\n",
    "       agg_1min_data as a\n",
    "       on t.epoch = a.epoch_key\n",
    "\"\"\")\n",
    "\n",
    "before_win_df.createOrReplaceTempView('before_win_df')\n",
    "before_win_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "44f73ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/19 17:18:06 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:06 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:07 WARN CSVHeaderChecker: CSV header does not conform to the schema.\n",
      " Header: , epoch\n",
      " Schema: index, epoch\n",
      "Expected: index but found: \n",
      "CSV file: file:///Users/ybatash/Workspace/tau.ac.il/tau-final-project/data/STG/datetime_data/dim_time.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 81:>   (0 + 3) / 3][Stage 82:>  (7 + 7) / 67][Stage 83:>  (0 + 0) / 67]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/19 17:18:08 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:08 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 83:=====>                                                  (6 + 10) / 67]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/19 17:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:10 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 85:>                                                       (0 + 10) / 11]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/19 17:18:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[Stage 85:>               (0 + 10) / 11][Stage 87:>                 (0 + 0) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/19 17:18:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:11 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "before_win_df.coalesce(10).write.mode(\"overwrite\").parquet(\"./data/STG/media_aggregated_data/before_window_functions\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "72b4633c",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.catalog.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e723bacf",
   "metadata": {},
   "source": [
    "# Create Diffrent Minute widows aggregate function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a92dc3b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- index: integer (nullable = true)\n",
      " |-- epoch: integer (nullable = true)\n",
      " |-- ts_: string (nullable = true)\n",
      " |-- date_: date (nullable = true)\n",
      " |-- year_: integer (nullable = true)\n",
      " |-- month_: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- day_of_month: integer (nullable = true)\n",
      " |-- time_: string (nullable = true)\n",
      " |-- hour_: integer (nullable = true)\n",
      " |-- minute_: integer (nullable = true)\n",
      " |-- snp_media_events_count: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bwf_df = spark.read.parquet(\"./data/STG/media_aggregated_data/before_window_functions/part-*\")\n",
    "bwf_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f066e841",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "window_spec = Window.orderBy(F.col(\"epoch\"))\n",
    "\n",
    "min_results_df = bwf_df.withColumn(\"rnk\", F.dense_rank().over(window_spec)) \\\n",
    "    .withColumn(\"m_avg_snp_media_events_count_last_15min\", \n",
    "                F.avg(\"snp_media_events_count\").over(window_spec.rowsBetween(-15, -1))) \\\n",
    "    .withColumn(\"m_max_snp_media_events_count_last_15min\", \n",
    "                F.max(\"snp_media_events_count\").over(window_spec.rowsBetween(-15, -1))) \\\n",
    "    .withColumn(\"m_stddev_snp_media_events_count_last_15min\", \n",
    "                F.stddev(\"snp_media_events_count\").over(window_spec.rowsBetween(-15, -1))) \\\n",
    "    .withColumn(\"m_sum_snp_media_events_count_last_15min\", \n",
    "                F.sum(\"snp_media_events_count\").over(window_spec.rowsBetween(-15, -1))) \\\n",
    "    .withColumn(\"m_avg_snp_media_events_count_last_30min\", \n",
    "                F.avg(\"snp_media_events_count\").over(window_spec.rowsBetween(-30, -1))) \\\n",
    "    .withColumn(\"m_max_snp_media_events_count_last_30min\", \n",
    "                F.max(\"snp_media_events_count\").over(window_spec.rowsBetween(-30, -1))) \\\n",
    "    .withColumn(\"m_stddev_snp_media_events_count_last_30min\", \n",
    "                F.stddev(\"snp_media_events_count\").over(window_spec.rowsBetween(-30, -1))) \\\n",
    "    .withColumn(\"m_sum_snp_media_events_count_last_30min\", \n",
    "                F.sum(\"snp_media_events_count\").over(window_spec.rowsBetween(-30, -1))) \\\n",
    "    .withColumn(\"m_avg_snp_media_events_count_last_45min\", \n",
    "                F.avg(\"snp_media_events_count\").over(window_spec.rowsBetween(-45, -1))) \\\n",
    "    .withColumn(\"m_max_snp_media_events_count_last_45min\", \n",
    "                F.max(\"snp_media_events_count\").over(window_spec.rowsBetween(-45, -1))) \\\n",
    "    .withColumn(\"m_stddev_snp_media_events_count_last_45min\", \n",
    "                F.stddev(\"snp_media_events_count\").over(window_spec.rowsBetween(-45, -1))) \\\n",
    "    .withColumn(\"m_sum_snp_media_events_count_last_45min\", \n",
    "                F.sum(\"snp_media_events_count\").over(window_spec.rowsBetween(-45, -1))) \\\n",
    "    .withColumn(\"m_avg_snp_media_events_count_last_1hour\", \n",
    "                F.avg(\"snp_media_events_count\").over(window_spec.rowsBetween(-60, -1))) \\\n",
    "    .withColumn(\"m_max_snp_media_events_count_last_1hour\", \n",
    "                F.max(\"snp_media_events_count\").over(window_spec.rowsBetween(-60, -1))) \\\n",
    "    .withColumn(\"m_stddev_snp_media_events_count_last_1hour\", \n",
    "                F.stddev(\"snp_media_events_count\").over(window_spec.rowsBetween(-60, -1))) \\\n",
    "    .withColumn(\"m_sum_snp_media_events_count_last_1hour\", \n",
    "                F.sum(\"snp_media_events_count\").over(window_spec.rowsBetween(-60, -1))) \\\n",
    "    .withColumn(\"m_avg_snp_media_events_count_last_3hour\", \n",
    "                F.avg(\"snp_media_events_count\").over(window_spec.rowsBetween(-180, -1))) \\\n",
    "    .withColumn(\"m_max_snp_media_events_count_last_3hour\", \n",
    "                F.max(\"snp_media_events_count\").over(window_spec.rowsBetween(-180, -1))) \\\n",
    "    .withColumn(\"m_stddev_snp_media_events_count_last_3hour\", \n",
    "                F.stddev(\"snp_media_events_count\").over(window_spec.rowsBetween(-180, -1))) \\\n",
    "    .withColumn(\"m_sum_snp_media_events_count_last_3hour\", \n",
    "                F.sum(\"snp_media_events_count\").over(window_spec.rowsBetween(-180, -1)))\\\n",
    "    .select(\"epoch\",\n",
    "            \"m_avg_snp_media_events_count_last_15min\",\n",
    "            \"m_max_snp_media_events_count_last_15min\",\n",
    "            \"m_stddev_snp_media_events_count_last_15min\",\n",
    "            \"m_sum_snp_media_events_count_last_15min\",\n",
    "            \"m_avg_snp_media_events_count_last_30min\",\n",
    "            \"m_max_snp_media_events_count_last_30min\",\n",
    "            \"m_stddev_snp_media_events_count_last_30min\",\n",
    "            \"m_sum_snp_media_events_count_last_30min\",\n",
    "            \"m_avg_snp_media_events_count_last_45min\",\n",
    "            \"m_max_snp_media_events_count_last_45min\",\n",
    "            \"m_stddev_snp_media_events_count_last_45min\",\n",
    "            \"m_sum_snp_media_events_count_last_45min\",\n",
    "            \"m_avg_snp_media_events_count_last_1hour\",\n",
    "            \"m_max_snp_media_events_count_last_1hour\",\n",
    "            \"m_stddev_snp_media_events_count_last_1hour\",\n",
    "            \"m_sum_snp_media_events_count_last_1hour\",\n",
    "            \"m_avg_snp_media_events_count_last_3hour\",\n",
    "            \"m_max_snp_media_events_count_last_3hour\",\n",
    "            \"m_stddev_snp_media_events_count_last_3hour\",\n",
    "            \"m_sum_snp_media_events_count_last_3hour\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "503cc470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/19 17:18:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:15 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:16 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "min_results_df.write.mode(\"overwrite\").parquet(\"./data/STG/media_aggregated_data/minute_windows_aggregate_function\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d33ff0",
   "metadata": {},
   "source": [
    "#  Create Diffrent Days intervals widows aggregate function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "10e2b6c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bwf_df.createOrReplaceTempView(\"bwf_df\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "568bf86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "snp_media_events_per_day_df = spark.sql(\"\"\"\n",
    "\n",
    "select  date_,\n",
    "        sum(snp_media_events_count) as snp_media_events_count\n",
    "from bwf_df\n",
    "group by date_\n",
    "\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "# df.filter(F.col(\"date_\") == \"2022-03-28\").filter(F.col(\"snp_media_events_count\")!=0).show(100000,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21e30187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from pyspark.sql.window import Window\n",
    "# # from pyspark.sql.functions import avg, dense_rank, col\n",
    "\n",
    "window_spec = Window.orderBy(F.col(\"date_\"))\n",
    "\n",
    "days_results_df = snp_media_events_per_day_df.withColumn(\"rnk\", F.dense_rank().over(window_spec)) \\\n",
    "    .withColumn(\"m_avg_snp_media_events_count_last_3days\", \n",
    "                F.avg(\"snp_media_events_count\").over(window_spec.rowsBetween(-3, -1))) \\\n",
    "    .withColumn(\"m_max_snp_media_events_count_last_3days\", \n",
    "                F.max(\"snp_media_events_count\").over(window_spec.rowsBetween(-3, -1))) \\\n",
    "    .withColumn(\"m_stddev_snp_media_events_count_last_3days\", \n",
    "                F.stddev(\"snp_media_events_count\").over(window_spec.rowsBetween(-3, -1))) \\\n",
    "    .withColumn(\"m_sum_snp_media_events_count_last_3days\", \n",
    "                F.sum(\"snp_media_events_count\").over(window_spec.rowsBetween(-3, -1)))\\\n",
    "    .withColumn(\"m_avg_snp_media_events_count_last_7days\", \n",
    "                F.avg(\"snp_media_events_count\").over(window_spec.rowsBetween(-7, -1))) \\\n",
    "    .withColumn(\"m_max_snp_media_events_count_last_7days\", \n",
    "                F.max(\"snp_media_events_count\").over(window_spec.rowsBetween(-7, -1))) \\\n",
    "    .withColumn(\"m_stddev_snp_media_events_count_last_7days\", \n",
    "                F.stddev(\"snp_media_events_count\").over(window_spec.rowsBetween(-7, -1))) \\\n",
    "    .withColumn(\"m_sum_snp_media_events_count_last_7days\", \n",
    "                F.sum(\"snp_media_events_count\").over(window_spec.rowsBetween(-7, -1))) \\\n",
    "    .withColumn(\"m_avg_snp_media_events_count_last_14days\", \n",
    "                F.avg(\"snp_media_events_count\").over(window_spec.rowsBetween(-14, -1))) \\\n",
    "    .withColumn(\"m_max_snp_media_events_count_last_14days\", \n",
    "                F.max(\"snp_media_events_count\").over(window_spec.rowsBetween(-14, -1))) \\\n",
    "    .withColumn(\"m_stddev_snp_media_events_count_last_14days\", \n",
    "                F.stddev(\"snp_media_events_count\").over(window_spec.rowsBetween(-14, -1))) \\\n",
    "    .withColumn(\"m_sum_snp_media_events_count_last_14days\", \n",
    "                F.sum(\"snp_media_events_count\").over(window_spec.rowsBetween(-14, -1)))\\\n",
    "    .withColumn(\"m_avg_snp_media_events_count_last_30days\", \n",
    "                F.avg(\"snp_media_events_count\").over(window_spec.rowsBetween(-30, -1))) \\\n",
    "    .withColumn(\"m_max_snp_media_events_count_last_30days\", \n",
    "                F.max(\"snp_media_events_count\").over(window_spec.rowsBetween(-30, -1))) \\\n",
    "    .withColumn(\"m_stddev_snp_media_events_count_last_30days\", \n",
    "                F.stddev(\"snp_media_events_count\").over(window_spec.rowsBetween(-30, -1))) \\\n",
    "    .withColumn(\"m_sum_snp_media_events_count_last_30days\", \n",
    "                F.sum(\"snp_media_events_count\").over(window_spec.rowsBetween(-30, -1)))\\\n",
    "    .withColumn(\"m_avg_snp_media_events_count_last_60days\", \n",
    "                F.avg(\"snp_media_events_count\").over(window_spec.rowsBetween(-60, -1))) \\\n",
    "    .withColumn(\"m_max_snp_media_events_count_last_60days\", \n",
    "                F.max(\"snp_media_events_count\").over(window_spec.rowsBetween(-60, -1))) \\\n",
    "    .withColumn(\"m_stddev_snp_media_events_count_last_60days\", \n",
    "                F.stddev(\"snp_media_events_count\").over(window_spec.rowsBetween(-60, -1))) \\\n",
    "    .withColumn(\"m_sum_snp_media_events_count_last_60days\", \n",
    "                F.sum(\"snp_media_events_count\").over(window_spec.rowsBetween(-60, -1))) \\\n",
    "        .select(\"date_\",\n",
    "                \"m_avg_snp_media_events_count_last_3days\",\n",
    "                \"m_max_snp_media_events_count_last_3days\",\n",
    "                \"m_stddev_snp_media_events_count_last_3days\",\n",
    "                \"m_sum_snp_media_events_count_last_3days\",\n",
    "                \"m_avg_snp_media_events_count_last_7days\",\n",
    "                \"m_max_snp_media_events_count_last_7days\",\n",
    "                \"m_stddev_snp_media_events_count_last_7days\",\n",
    "                \"m_sum_snp_media_events_count_last_7days\",\n",
    "                \"m_avg_snp_media_events_count_last_14days\",\n",
    "                \"m_max_snp_media_events_count_last_14days\",\n",
    "                \"m_stddev_snp_media_events_count_last_14days\",\n",
    "                \"m_sum_snp_media_events_count_last_14days\",\n",
    "                \"m_avg_snp_media_events_count_last_30days\",\n",
    "                \"m_max_snp_media_events_count_last_30days\",\n",
    "                \"m_stddev_snp_media_events_count_last_30days\",\n",
    "                \"m_sum_snp_media_events_count_last_30days\",\n",
    "                \"m_avg_snp_media_events_count_last_60days\",\n",
    "                \"m_max_snp_media_events_count_last_60days\",\n",
    "                \"m_stddev_snp_media_events_count_last_60days\",\n",
    "                \"m_sum_snp_media_events_count_last_60days\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "81cda689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/08/19 17:18:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:46 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "23/08/19 17:18:47 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "days_results_df.write.mode(\"overwrite\").parquet(\"./data/STG/media_aggregated_data/days_windows_aggregate_function\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7d4a2d9",
   "metadata": {},
   "source": [
    "# Create Final Media File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0cbb2669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- epoch: integer (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_15min: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_15min: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_15min: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_15min: long (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_30min: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_30min: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_30min: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_30min: long (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_45min: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_45min: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_45min: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_45min: long (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_1hour: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_1hour: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_1hour: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_1hour: long (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_3hour: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_3hour: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_3hour: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_3hour: long (nullable = true)\n",
      "\n",
      "root\n",
      " |-- date_: date (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_3days: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_3days: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_3days: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_3days: long (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_7days: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_7days: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_7days: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_7days: long (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_14days: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_14days: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_14days: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_14days: long (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_30days: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_30days: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_30days: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_30days: long (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_60days: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_60days: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_60days: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_60days: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "min_df = spark.read.parquet(\"./data/STG/media_aggregated_data/minute_windows_aggregate_function/*.parquet\")\n",
    "min_df.createOrReplaceTempView(\"min_df\")\n",
    "days_df = spark.read.parquet(\"./data/STG/media_aggregated_data/days_windows_aggregate_function/*.parquet\")\n",
    "days_df.createOrReplaceTempView(\"days_df\")\n",
    "\n",
    "min_df.printSchema()\n",
    "days_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "16d21e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- epoch: integer (nullable = true)\n",
      " |-- ts_: string (nullable = true)\n",
      " |-- date_: date (nullable = true)\n",
      " |-- year_: integer (nullable = true)\n",
      " |-- month_: integer (nullable = true)\n",
      " |-- day_of_week: string (nullable = true)\n",
      " |-- day_of_month: integer (nullable = true)\n",
      " |-- time_: string (nullable = true)\n",
      " |-- hour_: integer (nullable = true)\n",
      " |-- minute_: integer (nullable = true)\n",
      " |-- snp_media_events_count: long (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_15min: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_15min: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_15min: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_15min: long (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_30min: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_30min: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_30min: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_30min: long (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_45min: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_45min: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_45min: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_45min: long (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_1hour: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_1hour: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_1hour: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_1hour: long (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_3hour: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_3hour: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_3hour: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_3hour: long (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_3days: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_3days: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_3days: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_3days: long (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_7days: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_7days: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_7days: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_7days: long (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_14days: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_14days: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_14days: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_14days: long (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_30days: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_30days: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_30days: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_30days: long (nullable = true)\n",
      " |-- m_avg_snp_media_events_count_last_60days: double (nullable = true)\n",
      " |-- m_max_snp_media_events_count_last_60days: long (nullable = true)\n",
      " |-- m_stddev_snp_media_events_count_last_60days: double (nullable = true)\n",
      " |-- m_sum_snp_media_events_count_last_60days: long (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "media_df = bwf_df \\\n",
    "            .join(min_df, \"epoch\") \\\n",
    "            .join(days_df, \"date_\") \\\n",
    "            . select( \"epoch\",\n",
    "                      \"ts_\",\n",
    "                      \"date_\",\n",
    "                      \"year_\",\n",
    "                      \"month_\",\n",
    "                      \"day_of_week\",\n",
    "                      \"day_of_month\",\n",
    "                      \"time_\",\n",
    "                      \"hour_\",\n",
    "                      \"minute_\",\n",
    "                      \"snp_media_events_count\",\n",
    "                      \"m_avg_snp_media_events_count_last_15min\",\n",
    "                      \"m_max_snp_media_events_count_last_15min\",\n",
    "                      \"m_stddev_snp_media_events_count_last_15min\",\n",
    "                      \"m_sum_snp_media_events_count_last_15min\",\n",
    "                      \"m_avg_snp_media_events_count_last_30min\",\n",
    "                      \"m_max_snp_media_events_count_last_30min\",\n",
    "                      \"m_stddev_snp_media_events_count_last_30min\",\n",
    "                      \"m_sum_snp_media_events_count_last_30min\",\n",
    "                      \"m_avg_snp_media_events_count_last_45min\",\n",
    "                      \"m_max_snp_media_events_count_last_45min\",\n",
    "                      \"m_stddev_snp_media_events_count_last_45min\",\n",
    "                      \"m_sum_snp_media_events_count_last_45min\",\n",
    "                      \"m_avg_snp_media_events_count_last_1hour\",\n",
    "                      \"m_max_snp_media_events_count_last_1hour\",\n",
    "                      \"m_stddev_snp_media_events_count_last_1hour\",\n",
    "                      \"m_sum_snp_media_events_count_last_1hour\",\n",
    "                      \"m_avg_snp_media_events_count_last_3hour\",\n",
    "                      \"m_max_snp_media_events_count_last_3hour\",\n",
    "                      \"m_stddev_snp_media_events_count_last_3hour\",\n",
    "                      \"m_sum_snp_media_events_count_last_3hour\",\n",
    "                      \"m_avg_snp_media_events_count_last_3days\",\n",
    "                      \"m_max_snp_media_events_count_last_3days\",\n",
    "                      \"m_stddev_snp_media_events_count_last_3days\",\n",
    "                      \"m_sum_snp_media_events_count_last_3days\",\n",
    "                      \"m_avg_snp_media_events_count_last_7days\",\n",
    "                      \"m_max_snp_media_events_count_last_7days\",\n",
    "                      \"m_stddev_snp_media_events_count_last_7days\",\n",
    "                      \"m_sum_snp_media_events_count_last_7days\",\n",
    "                      \"m_avg_snp_media_events_count_last_14days\",\n",
    "                      \"m_max_snp_media_events_count_last_14days\",\n",
    "                      \"m_stddev_snp_media_events_count_last_14days\",\n",
    "                      \"m_sum_snp_media_events_count_last_14days\",\n",
    "                      \"m_avg_snp_media_events_count_last_30days\",\n",
    "                      \"m_max_snp_media_events_count_last_30days\",\n",
    "                      \"m_stddev_snp_media_events_count_last_30days\",\n",
    "                      \"m_sum_snp_media_events_count_last_30days\",\n",
    "                      \"m_avg_snp_media_events_count_last_60days\",\n",
    "                      \"m_max_snp_media_events_count_last_60days\",\n",
    "                      \"m_stddev_snp_media_events_count_last_60days\",\n",
    "                      \"m_sum_snp_media_events_count_last_60days\")\n",
    "     \n",
    "media_df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a2cf5761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "700321"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "media_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1d853bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "\n",
    "media_df.write.mode(\"overwrite\").parquet(\"./data/DWH/dim_media\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95982f5",
   "metadata": {},
   "source": [
    "# The End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eafea84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
